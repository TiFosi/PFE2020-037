{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json # print(json.dumps(text, indent=2))\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://sparql.archives-ouvertes.fr/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "sparql.setTimeout(10000000)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def execute(query):\n",
    "    queryString = \"\"\"\n",
    "        prefix hal:\t<http://data.archives-ouvertes.fr/schema/>\n",
    "        prefix vcard2006: <http://www.w3.org/2006/vcard/ns#>\n",
    "        prefix ns8:\t<http://fr.dbpedia.org/resource/>\n",
    "        prefix org: <http://www.w3.org/ns/org#>\n",
    "        prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        prefix dcterms: <http://purl.org/dc/terms/>\n",
    "        prefix fabio: <http://purl.org/spar/fabio/>\n",
    "        prefix ore:\t<http://www.openarchives.org/ore/terms/>\n",
    "        %s\n",
    "        \"\"\" % query\n",
    "    sparql.setQuery(queryString)\n",
    "    response = sparql.query().convert()\n",
    "    df = pd.json_normalize(response['results']['bindings'])\n",
    "    filter_col = [col for col in df if not col.endswith(('.type', '.datatype'))]\n",
    "    return df[filter_col]\n",
    "\n",
    "# 42970 authors with aggregate: 42808 with name, 162 without name\n",
    "# 1517974 authors without aggregate: 1346390 with name, 171584 without name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La requête permettant de récupérer la liste des auteurs qui ont changé de pays plus qu'une fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_authors = \"\"\"\n",
    "    select distinct ?author count(distinct ?country)\n",
    "    where {{\n",
    "        ?doc dcterms:creator ?n.\n",
    "        ?n hal:person ?author; hal:structure ?lab.\n",
    "        ?lab vcard2006:country-name ?country.\n",
    "    }}\n",
    "    group by ?author\n",
    "    having (count(distinct ?country) > 2)\n",
    "    limit {0} offset {1}\n",
    "\"\"\"\n",
    "\n",
    "authors = execute(query_authors.format(100, 0))\n",
    "# authors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La requête permettant de récupérer les informations nécessaires pour un auteur en particulier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data = \"\"\"\n",
    "    select distinct\n",
    "        ?author \n",
    "        ?doc \n",
    "            str(?title) as ?title \n",
    "            str(?versionOf) as ?versionOf \n",
    "            xsd:date(?issued) as ?issuedAt \n",
    "        ?lab ?labName \n",
    "        replace(str(?country), 'http://fr.dbpedia.org/resource/', '') AS ?country \n",
    "        concat(str(xsd:date(?available)), '') as ?availableAt\n",
    "        concat(str(?nameAgg), '') as ?nameAgg \n",
    "        concat(str(?nameDoc), '') as ?nameDoc\n",
    "        concat(str(?adress), '') as ?adress\n",
    "    where {{\n",
    "        ?doc dcterms:creator ?n;\n",
    "            dcterms:issued ?issued.\n",
    "            optional {{ ?doc dcterms:available ?available }}\n",
    "            optional {{ ?doc dcterms:title ?title }}\n",
    "            optional {{ ?doc dcterms:isVersionOf ?versionOf }}\n",
    "        ?n hal:person {0}; hal:structure ?lab.\n",
    "        ?lab skos:prefLabel ?labName;\n",
    "            vcard2006:country-name ?country.\n",
    "            optional {{ ?lab org:siteAddress ?adress }}\n",
    "        optional {{ ?authorAgg ore:aggregates {0} optional {{ ?authorAgg foaf:name ?nameAgg }} }}\n",
    "        optional {{ {0} foaf:name ?nameDoc }}\n",
    "        bind( if(bound(?authorAgg), ?authorAgg, {0} ) as ?author )\n",
    "        filter(bound(?nameAgg) or bound(?nameDoc))\n",
    "    }}\n",
    "    limit {1} offset {2}\n",
    "\"\"\"\n",
    "limit = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporter les données des auteurs sélectionnés dans un fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'w'\n",
    "for row in authors.values.tolist():\n",
    "    authorId = '<'+ row[0] +'>'\n",
    "\n",
    "    offset = 0\n",
    "    result = execute( query_data.format( authorId, limit, offset) ).fillna('')\n",
    "    while len(result):\n",
    "        header = False if mode == 'a' else list(result.columns)\n",
    "        result.sort_values(['author.value', 'issuedAt.value'], axis = 0, ascending = True,\n",
    "                           inplace = True, na_position ='last')\n",
    "        result.to_csv('output/data.csv', sep=',', index=False, header=header, mode=mode)\n",
    "        mode = 'a'\n",
    "        offset += limit\n",
    "        result = execute( query_data.format( authorId, limit, offset) ) # .fillna('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lire le fichier CSV exporté précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"output/data.csv\").fillna('')\n",
    "# list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regrouper les données par auteur, par année et par pays dans un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "byAuthorDict = {}\n",
    "for row in data.values.tolist():\n",
    "    authorURI = row[0]\n",
    "    year, mont, date = row[4].split('-')\n",
    "    country = row[7]\n",
    "\n",
    "    if authorURI not in byAuthorDict:\n",
    "        byAuthorDict[ authorURI ] = {}\n",
    "\n",
    "    if year not in byAuthorDict[ authorURI ]:\n",
    "        byAuthorDict[ authorURI ][ year ] = {}\n",
    "\n",
    "    if country not in byAuthorDict[ authorURI ][ year ]:\n",
    "        byAuthorDict[ authorURI ][ year ][ country ] = []\n",
    "\n",
    "    byAuthorDict[ authorURI ][ year ][ country ].append({\n",
    "        # 'author': row[0],\n",
    "        'docURI': row[1],\n",
    "        'docTitle': row[2],\n",
    "        'versionOf': row[3],\n",
    "        'issuedAt': row[4],\n",
    "        'lab': row[5],\n",
    "        'labName': row[6],\n",
    "        # 'country': row[7],\n",
    "        'availableAt': row[8],\n",
    "        'name1': row[9],\n",
    "        'name2': row[10],\n",
    "        'adress': row[11],\n",
    "    })\n",
    "# byAuthorDict\n",
    "\n",
    "byAuthorList = []\n",
    "for authorURI in byAuthorDict:\n",
    "    names = set()\n",
    "\n",
    "    authorData = []\n",
    "    for year in byAuthorDict[ authorURI ]:\n",
    "        yearData = []\n",
    "        for country in byAuthorDict[ authorURI ][ year ]:\n",
    "            docs = []\n",
    "            for doc in byAuthorDict[ authorURI ][ year ][ country ]:\n",
    "                if doc['name1']:\n",
    "                    names.add(doc['name1'])\n",
    "                if doc['name2']:\n",
    "                    names.add(doc['name2'])\n",
    "\n",
    "                docs.append( {k:doc[k] for k in ['docURI', 'versionOf', 'docTitle', 'labName']} )\n",
    "\n",
    "            yearData.append({ 'country': country,\n",
    "                'docs': docs\n",
    "            })\n",
    "\n",
    "        authorData.append({ 'year': year,\n",
    "            'byCountry': yearData\n",
    "        })\n",
    "\n",
    "    byAuthorList.append({ 'authorURI': authorURI, # .replace(\"https://data.archives-ouvertes.fr/author/\", \"\"),\n",
    "        'name': list(names)[0] if len(names) == 1 else list(names),\n",
    "        'byYear': authorData\n",
    "    })\n",
    "\n",
    "with open('output/data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(byAuthorList, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créér le fichier JSON pour générer le Sankey diagram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1\n",
    "nodes = []\n",
    "links = []\n",
    "nodesMap = {}\n",
    "for author in byAuthorList:\n",
    "    name = author['name']\n",
    "    if isinstance(name, list):\n",
    "        name = '; '.join(name)\n",
    "    \n",
    "    index += 1\n",
    "    nodes.append({ 'id': index, 'name': name })\n",
    "    authIndex = index\n",
    "\n",
    "    authorData = author['byYear']\n",
    "    for i in range(len(authorData)):\n",
    "        if i == 0:\n",
    "            year = authorData[i]['year']\n",
    "            byCountry = authorData[i]['byCountry']\n",
    "\n",
    "            for countryData in byCountry:\n",
    "                index += 1\n",
    "                nodes.append({\n",
    "                    'id': index,\n",
    "                    'year': year,\n",
    "                    'country': countryData['country'],\n",
    "                })\n",
    "                nodesMap[ year + countryData['country'] ] = index\n",
    "\n",
    "                links.append({\n",
    "                    'source': authIndex,\n",
    "                    'target': index,\n",
    "                    'value': len(countryData['docs']),\n",
    "                    'publications': countryData['docs'],\n",
    "                })\n",
    "        else:\n",
    "            prevYear = authorData[i-1]['year']\n",
    "            currYear = authorData[i]['year']\n",
    "            for prevCountryData in authorData[i-1]['byCountry']:\n",
    "                for currCountryData in authorData[i]['byCountry']:\n",
    "\n",
    "                    prevNodeKey = prevYear + prevCountryData['country']\n",
    "                    currNodeKey = currYear + currCountryData['country']\n",
    "\n",
    "                    if prevNodeKey == currNodeKey:\n",
    "                        continue\n",
    "\n",
    "                    if prevNodeKey not in nodesMap:\n",
    "                        index += 1\n",
    "                        nodes.append({ 'id': index, 'year': prevYear, 'country': prevCountryData['country'] })\n",
    "                        nodesMap[ prevNodeKey ] = index\n",
    "\n",
    "                    if currNodeKey not in nodesMap:\n",
    "                        index += 1\n",
    "                        nodes.append({ 'id': index, 'year': currYear, 'country': currCountryData['country'] })\n",
    "                        nodesMap[ currNodeKey ] = index\n",
    "\n",
    "                    links.append({\n",
    "                        'source': nodesMap[ prevNodeKey ],\n",
    "                        'target': nodesMap[ currNodeKey ],\n",
    "                        'value': len(currCountryData['docs']),\n",
    "                        'publications': currCountryData['docs'],\n",
    "                    })\n",
    "\n",
    "with open('output/sankey-formatted.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({'nodes': nodes, 'links': links}, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
